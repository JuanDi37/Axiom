# Axiom ‚Äì Asistente jur√≠dico con LLM local

Axiom es un asistente jur√≠dico experimental pensado para abogados y estudios legales.  
Permite hacer preguntas en lenguaje natural y responde **citando fragmentos de normas**.

El modelo de lenguaje no se conecta a ninguna API externa:  
usa **Ollama** corriendo en mi m√°quina, con un modelo open-source (en mi caso `llama3.2`).

---

## Descripci√≥n general

La arquitectura es sencilla:

- **Frontend (web)**  
  Aplicaci√≥n en React que muestra:
  - Pantallas de landing, login/registro y chat.
  - Un chat tipo ‚ÄúGemini/ChatGPT‚Äù minimalista.
  - Preguntas r√°pidas y citas de las fuentes usadas en cada respuesta.

- **Backend (API)**  
  Servidor Node/Express que se encarga de:
  - Registro e inicio de sesi√≥n de usuarios (con SQLite).
  - Recibir las preguntas del chat.
  - Leer los trozos de documentos legales desde SQLite.
  - Llamar a Ollama con la pregunta + contexto legal.
  - Devolver respuesta + citas al frontend.

- **Motor LLM (Ollama)**  
  Ollama corre en la m√°quina host y expone un endpoint HTTP local.  
  El backend le env√≠a:
  - La pregunta del usuario.
  - El contexto: trozos de textos legales que se han indexado previamente.

- **Biblioteca legal**  
  Tus documentos legales (por ahora en `.txt`) se guardan en:
  - `data/legal_docs/`  
  Un script de ingesta los:
  - Lee.
  - Trocea en fragmentos.
  - Los guarda en las tablas `documents` y `chunks` de `app.db`.

---

## üõ†Ô∏è Tecnolog√≠as usadas

- **Frontend**